<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Trust_Derm</title>

<!-- 	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->

	<meta property="twitter:title" content="Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision." />
	<meta property="twitter:description" content="A human-in-the-loop framework for trustworthy skin cancer diagnosis." /> 
	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision</span>
		<table align=center width=1000px>
			<table align=center width=1000px>
				<tr>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.au/citations?view_op=list_works&hl=en&hl=en&user=GaHzugoAAAAJ">Siyuan Yan</a></span>
						</center>
					</td>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com/citations?user=9keYqYsAAAAJ&hl=en">Zhen Yu</a></span>
						</center>
					</td>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://www.researchgate.net/profile/Xuelin-Zhang-12">Xuelin Zhang</a></span>
						</center>
					</td>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.au/citations?user=j5K7HPoAAAAJ&hl=en">Dwarikanath Mahapatra</a></span>
						</center>
					</td>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.au/citations?user=tKe_olQAAAAJ&hl=en">Shekhar S. Chandra</a></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=800>
				<tr>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.au/citations?user=dJmvfEMAAAAJ&hl=en">Monika Janda</a></span>
						</center>
					</td>
						<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.au/citations?user=PyM9YoAAAAAJ&hl=en">Peter Soyer</a></span>
						</c
					</td>
					<td align=center width=20px>
						<center>
							<span style="font-size:18px"><a href="https://scholar.google.com.au/citations?user=Q0gUrcIAAAAJ&hl=en">Zongyuan Ge</a></span>
						</center>
					</td>				
				</tr>
			</table>
				<hr>


		<!--------------------- links --------------------->
    <div class="gap-10"></div>

 <!--    <center>
    <span style="font-size:20px">
      <b>CVPR 2023</b>

      [<a href="https://arxiv.org/pdf/2303.00885.pdf" target="_blank" style=" color:#007acc">Paper</a>]
      [<a href="https://arxiv.org/pdf/2303.00885.pdf" target="_blank" style=" color:#007acc">Arxiv</a>]

      [<a href=" " target="_blank"style=" color:#007acc">Poster</a>]

      [<a href=""target="_blank"style=" color:#007acc">Slides</a>]

      [<a href="" target="_blank" style=" color:#007acc">BibTeX</a>]


    </span>
    <div class="gap-20"></div>
    </center> -->
<style>
    .gap {
        margin-right: 0px;
    }
</style>
    
    
    <center>
    <span style="font-size:20px">
      <b>CVPR 2023</b>
       <span class="gap"></span>
      [<a href="https://arxiv.org/pdf/2303.00885.pdf" target="_blank" style="color:#007acc">Paper</a>]
   <span class="gap"></span>
      [<a href="https://arxiv.org/pdf/2303.00885.pdf" target="_blank" style="color:#007acc">Arxiv</a>]
       <span class="gap"></span>
      [<a href="" target="_blank" style="color:#007acc">Poster</a>]
       <span class="gap"></span>
      [<a href="" target="_blank" style="color:#007acc">Slides</a>]
       <span class="gap"></span>
       [<a href="./resources/bibtex.txt" target="_blank" style=" color:#007acc">BibTeX</a>]
    </span>
    <div class=".gap"></div>
</center>



	</center>



	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Deep neural networks have demonstrated promising performance on image recognition tasks. However, they may
				heavily rely on confounding factors, using irrelevant artifacts or bias within the dataset as the cue to improve performance. When a model performs decision-making based on
				these spurious correlations, it can become untrustable and
				lead to catastrophic outcomes when deployed in the realworld scene. In this paper, we explore and try to solve this
				problem in the context of skin cancer diagnosis. We introduce a human-in-the-loop framework in the model training
				process such that users can observe and correct the model's
				decision logic when confounding behaviors happen. Specifically, our method can automatically discover confounding
				factors by analyzing the co-occurrence behavior of the samples. It is capable of learning confounding concepts using
				easily obtained concept exemplars. By mapping the blackbox model's feature representation onto an explainable concept space, human users can interpret the concept and intervene via first order-logic instruction. We systematically
				evaluate our method on our newly crafted, well-controlled
				skin lesion dataset and several public skin lesion datasets.
				Experiments show that our method can effectively detect
				and remove confounding factors from datasets without any
				prior knowledge about the category distribution and does
				not require fully annotated concept labels. We also show
				that our method enables the model to focus on clinicalrelated concepts, improving the model's performance and
				trustworthiness during model inference.
			</td>
		</tr>
	</table>
	<br>


	<center><h1>Confounding Behaviors on Dermoscopic Images</h1></center>
	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:550px" src="./images/motivation.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
				Observed confounding concepts in ISIC2019-2020 datasets, the top row shows sample images, and the bottom row is the corresponding heatmap from GradCAM: (a) dark corners. (b) rulers. (c) dark borders. (e) dense hairs. (f) air pockets..	
				</td>
			</tr>
		</table>
	</center>

	<center><h1>A Human-in-the-loop Pipeline to Remove Confounders</h1></center>
	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:800px" src="./images/method.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
				Illustration of our human-in-the-loop pipeline. (a) Applying the spectral relevance analysis algorithm to discover the confounding factors within the dataset. (b) Learning confounding concept and clinical concept vectors. (c) Projecting feature representation of a model onto concept subspace and then removing the model's confounding behaviors via human interaction. Pig. denotes pigmentation, and Reg. denotes regression structure..	
				</td>
			</tr>
		</table>
	</center>
	
	<center><h1>Discovered Confounding Factors</h1></center>
	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:1000px" src="./images/gcdd1.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
				Global analysis of the models' behavior within datasets using GCCD. The left graph is the tSNE of spectral clustering using GradCAMs of a ResNet50 within ISIC2019 and ISIC2020. The right one is the tSNE of spectral clustering using GradCAMs of a VGG16 within the SynthDermdataset.
				</td>
			</tr>
			</table>

	</center>


		<center><h1>Global Explanation</h1></center>
	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:1000px" src="./images/exp1.png"/>
					</center>
				</td>
			</tr>
		</table>
			<table align=center width=850px>
			<tr>
				<td>
				The global explanation of the model’s behavior on the melanoma (dark corners) dataset of ConfDerm. In the left two figures, either the concept activation or logical rule shows that the model is confounded by the concept of the dark corners when predicting melanoma. In the right two figures, after the interaction, the model does not predict melanoma based on the dark corners, and it predicts melanoma based on meaningful clinical concepts.
				</td>
			</tr>
</table>
	</center>

		<center><h1>Quantitative Result</h1></center>
	<center>
		<table align=center width=750px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:550px" src="./images/exp2.png"/>
					</center>
				</td>
			</tr>
		</table>
			<table align=center width=850px>
			<tr>
				<td>
				Performance improvement on confounded class when removing different confounded classes using XIL in five confounded datasets in the ConfDerm dataset.
				</td>
			</tr>
			</table>

	</center>





	<br>
<!-- 	<hr> -->
	<center><h1>ConfDerm Dataset</h1></center>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					 We plan to release the dataset soon. Please refer to the paper to get the details of the dataset.
				</td>
			</tr>
		</table>
	</center>

<hr>

	<table align=center width=450px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Siyuan Yan, Zhen Yu, Xuelin Zhang, Dwarikanath Mahapatra, Shekhar S. Chandra, Monika Janda, Peter Soyer, Zongyuan Ge<br>
				<b>Towards Trustable Skin Cancer Diagnosis via Rewriting Model’s Decision</b><br>
				In CVPR, 2023.<br>
				(hosted on <a href="https://arxiv.org/pdf/2303.00885.pdf">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>


<hr>
	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project, the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>
	
	<hr>	
	<br>

<br>
</body>
</html>